---
author: "Abhishek Dhull"
output:
  html_document:
    toc: yes
---
## Introduction
This is document describes the analysis I conducted for my final project for the Johns Hopkins' Coursera course "Practical Machine Learning" in the Data Science specialization.  

## Method
First, split the training data into 90/10 subsamples.  
```{r}
set.seed(614)
library(lattice); library(ggplot2); library(caret)
pml.training <- read.csv("c:/coursera/R programming/working directory/pml-training.csv")
inTrain <- createDataPartition(y=pml.training$classe, p=0.9, list=FALSE)
training <- pml.training[inTrain,]
testing <- pml.training[-inTrain,]
```
The 90 percent subsample is used to train the modle, and the 10 percent sample is used for cross-validation.  I chose this simple cross-validation rather than using something like K-fold via the `cv.folds` option to cut down on execution time, which was already quite lengthy.  Next, I implement a Stochastic Gradient Boosting algorithm via the `gbm` package.
```{r}
ptm <- proc.time()
modFit <- train(classe ~ user_name + pitch_arm + yaw_arm + roll_arm 
                + roll_belt + pitch_belt + yaw_belt + gyros_belt_x 
                + gyros_belt_y + gyros_belt_z + accel_belt_x 
                + accel_belt_y + accel_belt_z + magnet_belt_x 
                + magnet_belt_y + magnet_belt_z + gyros_arm_x 
                + gyros_arm_y + gyros_arm_z + accel_arm_x 
                + accel_arm_y + accel_arm_z + magnet_arm_x 
                + magnet_arm_y + magnet_arm_z + roll_dumbbell 
                + pitch_dumbbell + yaw_dumbbell, method="gbm", 
                data=training, verbose=FALSE)
proc.time() - ptm
```

```{r}
print(modFit)
predictTr <- predict(modFit,training)
table(predictTr, training$classe)
```
The model correctly classifies 93.6 percent of the observations in the training sample using 150 trees.  The "roll_belt"" and "yaw_belt"" features were by far the most important in terms of variable influence.  
```{r}
summary(modFit,n.trees=150)
```

A plot of these top two features colored by outcome demonstrates their relative importance.  
```{r}
qplot(roll_belt, yaw_belt,colour=classe,data=training)
```

```{r}
ggplot(modFit)
```

```{r}
predictTe <- predict(modFit,testing)
table(predictTe, testing$classe)
```
The algorithm actually peforms only does slightly worse on the testing subset than it did on the full training set, correctly classifying 93.4 percent of the observations.

## Predicting on the Test Set
Finally, I use the algorithm to predict using the testing set.  The results are run through the `pml_write_files()` function from the course Coursera site, and stored for submission.  
```{r}
pml.testing <- read.csv("~/R/Coursera /Machine Learning/Project/pml-testing.csv")
answers <- as.character(predict(modFit, pml.testing))
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```
After submitting these answers, it turns out that the algorithm correctly predicted the outcome for 20/20 observations further confirming its strong out-of-sample classification accuracy.  